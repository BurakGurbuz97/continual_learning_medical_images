,Task1 Acc,Task2 Acc,Task3 Acc,Avg Acc
Eval After Task1,0.8179665803909302,0.8179665803909302
Eval After Task2,0.764484703540802,0.910552442073822,0.837518572807312
Eval After Task3,0.7433147430419922,0.8658286929130554,0.5894669890403748,0.7328701416651408

(remind_proj) amrit@saitama:~/Downloads/REMIND$ python launch.py --pretrain_epochs 10 --num_epochs 10 --dataset Microscopic
Using downloaded and verified file: /home/amrit/Downloads/datasets/pathmnist.npz
Using downloaded and verified file: /home/amrit/Downloads/datasets/pathmnist.npz
Using downloaded and verified file: /home/amrit/Downloads/datasets/bloodmnist.npz
Using downloaded and verified file: /home/amrit/Downloads/datasets/bloodmnist.npz
Using downloaded and verified file: /home/amrit/Downloads/datasets/tissuemnist.npz
Using downloaded and verified file: /home/amrit/Downloads/datasets/tissuemnist.npz
Using downloaded and verified file: /home/amrit/Downloads/datasets/pathmnist.npz
Using downloaded and verified file: /home/amrit/Downloads/datasets/pathmnist.npz
REMIND_F(
  (conv): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc): Sequential(
    (0): Linear(in_features=8192, out_features=2000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=2000, out_features=9, bias=True)
  )
) REMIND_G(
  (conv): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
Weights not found. Pretraining feature_extract_G
Pretrain Epoch: 1/10, Loss: 1.2477880716323853
Pretrain Epoch: 2/10, Loss: 0.9445071816444397
Pretrain Epoch: 3/10, Loss: 0.4261118173599243
Pretrain Epoch: 4/10, Loss: 0.6382043957710266
Pretrain Epoch: 5/10, Loss: 0.5346593260765076
Pretrain Epoch: 6/10, Loss: 0.5091921091079712
Pretrain Epoch: 7/10, Loss: 0.3074113130569458
Pretrain Epoch: 8/10, Loss: 0.3038175404071808
Pretrain Epoch: 9/10, Loss: 0.26874691247940063
Pretrain Epoch: 10/10, Loss: 0.15315872430801392
Test Accuracy: 83.16155988857939%
Feature Extractor: REMIND_G(
  (conv): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
Classifier: REMIND_F(
  (conv): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc): Sequential(
    (0): Linear(in_features=8192, out_features=2000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=2000, out_features=25, bias=True)
  )
)

Training Product Quantizer
Completed in 39.203229904174805 secs

Creating Memory
Memory size in samples:  2500
****** Learning Episode-1   Classes: [0, 1, 2, 3, 4, 5, 6, 7, 8] ******
Epoch: 1/10, Loss: 0.7319257023591029
Epoch: 2/10, Loss: 0.5722781917716881
Epoch: 3/10, Loss: 0.48592546472192377
Epoch: 4/10, Loss: 0.42837307766032773
Epoch: 5/10, Loss: 0.3851059598730337
Epoch: 6/10, Loss: 0.3512110867132808
Epoch: 7/10, Loss: 0.3223997205866344
Epoch: 8/10, Loss: 0.29795030247467247
Epoch: 9/10, Loss: 0.27686592732830023
Epoch: 10/10, Loss: 0.258082344548047
Pushing codes to memory
Current Task: 1 --> Accuracy on Task-1 is 0.82  (Scenario: CIL)
****** Learning Episode-2   Classes: [9, 10, 11, 12, 13, 14, 15, 16] ******
Epoch: 1/10, Loss: 1.9766144908609842
Epoch: 2/10, Loss: 1.2085151463037438
Epoch: 3/10, Loss: 0.9066445861780451
Epoch: 4/10, Loss: 0.7384197715492474
Epoch: 5/10, Loss: 0.6282651907631327
Epoch: 6/10, Loss: 0.5514703920140623
Epoch: 7/10, Loss: 0.49282394942580426
Epoch: 8/10, Loss: 0.44740625779100107
Epoch: 9/10, Loss: 0.40953874820596947
Epoch: 10/10, Loss: 0.3789758202043317
Pushing codes to memory
Current Task: 2 --> Accuracy on Task-1 is 0.76  (Scenario: CIL)
Current Task: 2 --> Accuracy on Task-2 is 0.91  (Scenario: CIL)
****** Learning Episode-3   Classes: [17, 18, 19, 20, 21, 22, 23, 24] ******
Epoch: 1/10, Loss: 0.8190525925097902
Epoch: 2/10, Loss: 0.723126097718533
Epoch: 3/10, Loss: 0.6812209466785385
Epoch: 4/10, Loss: 0.6551415850240071
Epoch: 5/10, Loss: 0.6357842705335983
Epoch: 6/10, Loss: 0.6205450558860773
Epoch: 7/10, Loss: 0.6076714349432033
Epoch: 8/10, Loss: 0.5964592961071912
Epoch: 9/10, Loss: 0.5862809347363187
Epoch: 10/10, Loss: 0.5768587475953535
Pushing codes to memory
Current Task: 3 --> Accuracy on Task-1 is 0.74  (Scenario: CIL)
Current Task: 3 --> Accuracy on Task-2 is 0.87  (Scenario: CIL)
Current Task: 3 --> Accuracy on Task-3 is 0.59  (Scenario: CIL)
